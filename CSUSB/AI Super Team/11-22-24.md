Nemu tron
and qwen2.5

These models were good for "low end specs". 


---
### Links for LMM Hacking
[https://github.com/verazuo/jailbreak_llms](https://github.com/verazuo/jailbreak_llms)  
[https://github.com/forcesunseen/llm-hackers-handbook](https://github.com/forcesunseen/llm-hackers-handbook)  
[https://doublespeak.chat/#/](https://doublespeak.chat/#/)  
[https://owasp.org/www-project-llm-prompt-hacking/](https://owasp.org/www-project-llm-prompt-hacking/)


"Non vision models should run"

Look into setting up ollama locally, and getting it to communicate with Docker> 
settings --> Connections

[http://host.docker.internal:11434](http://host.docker.internal:11434)


